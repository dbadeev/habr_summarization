# Суммаризация статей Habr с использованием YaGPT
---
## Постановка задачи

Цель проекта - построение автоматической [абстрактивной суммаризации](https://habr.com/ru/articles/514540/#:~:text=%D0%90%D0%B1%D1%81%D1%82%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%B0%D1%8F%20%D1%81%D1%83%D0%BC%D0%BC%D0%B0%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F) статей из Habr с качеством, не хуже заданного бейзлайна. <br><br>
Для 100 статей, собранных в файле данных, необходимо: <br>
   * _Построить автоматическую абстрактивную суммаризацию_
   * _Получить качество суммаризаций не хуже (с учетом статзначимости), чем у выбранного бейзлайна по оценке **закрытой** модели_
   * _Получить качество суммаризаций не хуже, чем `= 0.557`по оценке открытой модели_
   * _Оформить результат в нужном формате_

**_Замечание:_**
Закрытая модель используется, так как тестовые данные и модель для оценки качества открыты. Т.е. можно переобучиться и "обмануть" открытую модель оценки качества методом перебора.<br><br>

### Оценка качества
- Качество оценивается моделью, обученной на метрику **SEAHORSE Q6 Concise**:
   - Статья [_SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation_](https://arxiv.org/abs/2305.13194)
   - [Данные и метрики](https://github.com/google-research-datasets/seahorse) от авторов 
- Обучение модели качества:
   - RU и EN данные взяты из статьи [_SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation_](https://arxiv.org/abs/2305.13194)
   - Для предсказания **Q6 Concise** модель-метрика обучена  из датасета статьи (самая высокоуровневая метрика из предложенных)
      - 10% данных использовалось для dev/test
      - 90% данных использовалось для обучения модели (обучено ДВЕ модели: открытая и закрытая. Каждая из моделей обучена на 60% данных от полного датасета).

**_Замечание:_**
На вход модели-метрике текст должен подаваться в следующем формате: `"Текст статьи:\n" + Text + "\n\n" + "Краткое содержание:\n" + Summary as metric_input`

### Формат результата выполненного задания
- `json lines` - в каждой строке json вида `{'id': AAA, 'summary': "BBB"}`

### Что в архиве
- `test_articles_clear_100.json` - статьи, которые нужно суммаризовать.
- `train_data.json` - примеры различных суммаризаций с оценкой открытой моделью, которые можно использовать для дообучения при необхдимости.
- `example.ipynb` - jupyter ноутбук с примерами чтения данных и того, как записывать решение, то есть выходного формата. Также приведен пример запроса в API для замера качества суммаризаций во время разработки решения. 


## Начало Работы

### Копирование
Для копирования файлов Проекта на локальный компьютер в папку *<your_dir_on_local_computer>* выполните:

```
    $ git clone git@github.com:dbadeev/habr_summarization.git <your_dir_on_local_computer>
```

### Описание файлов
* *tweets.pdf* - текст задания
* *requirements.txt* - список библиотек, необходимых для работы
* Папка *data*
  - *processedNegative.csv* - файл с твитами негативной тональности
  - *processedNeutral.csv*  - файл с твитами нейтральной тональности
  - *processedPositive.csv*  - файл с твитами позитивной тональности
* *tweets.ipynb* - ноутбук проекта  
* *text_cleaninig.py* - утилиты "чистки" текста твитов
* *text_processing.py* - утилиты векторизации текста твитов
* *w2v_ml.py* - утилиты векторизации с помощью Word2Vec и предварительно обученных моделей представления векторов слов
* *cosine_similarity.py* - утилиты вычисления косинусного сходства векторов представлений слов
* *machine_learning.py* - утилиты нахождения оптимальных параметров различных моделей машинного обучения для подсчета accuracy с помощью GridSearch
* Папка *res*
  - *cos_sim.csv* - файл с 10 наиболее схожими парами твитов среди датасетов, полученных в результате использования различных подходов к предварительной обработке данных 
  - *df_df_prep.csv*  - файл с твитами, полученными в результате использования различных подходов к предварительной обработке данных 
<br>

## Запуск
В файле *tweets.ipynb* приведена пошаговая реализация проекта с пояснениями и промежуточными результатами. 

Мы собрали несколько тысяч статей с Habr, для 100 из них предстоит построить автоматическую абстрактивную суммаризацию. 
### Что нужно сделать
 - Построить суммаризации для 100 статей из файла `test_articles_clear_100.json`
 - Суммаризации оформить в нужном формате и отправить на проверку
 

### Как оценивается качество
- Качество будет оцениваться моделью, обученной на метрику **SEAHORSE Q6 Concise** 
    - Статья https://arxiv.org/abs/2305.13194
    - Данные и метрики от авторов https://github.com/google-research-datasets/seahorse
- Про обучение модели качества:
        - Мы взяли RU и EN данные из статьи SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation https://arxiv.org/abs/2305.13194
        - Обучили модель-метрику предсказывать Q6 Concise из датасета статьи (как самую высокоуровневую метрику из предложенных)
        - 10% данных ушло на dev/test
        - 90% данных ушло на обучение модели (мы обучили 2 модели, открытую и закрытую, каждая из моделей обучена на 60% данных от полного датасета)

- На вход метрике-модели текст подается в следующем формате: `"Текст статьи:\n" + Text + "\n\n" + "Краткое содержание:\n" + Summary as metric_input`




