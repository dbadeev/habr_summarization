# Суммаризация статей Habr с использованием YaGPT
---
## Постановка задачи

Цель проекта - построение автоматической [абстрактивной суммаризации](https://habr.com/ru/articles/514540/#:~:text=%D0%90%D0%B1%D1%81%D1%82%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%B0%D1%8F%20%D1%81%D1%83%D0%BC%D0%BC%D0%B0%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F) статей из Habr с качеством, не хуже заданного бейзлайна. <br><br>
Для 100 статей, собранных в файле данных, необходимо: <br>
   * _Построить автоматическую абстрактивную суммаризацию_
   * _Получить качество суммаризаций не хуже (с учетом статзначимости), чем у выбранного бейзлайна по оценке **закрытой** модели_
   * _Получить качество суммаризаций не хуже, чем `= 0.557`по оценке открытой модели_
   * _Оформить результат в нужном формате_

**_Замечание:_**
Закрытая модель используется, так как тестовые данные и модель для оценки качества открыты. Т.е. можно переобучиться и "обмануть" открытую модель оценки качества методом перебора.<br><br>

### Оценка качества
- Качество оценивается моделью, обученной на метрику **SEAHORSE Q6 Concise**:
   - Статья [_SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation_](https://arxiv.org/abs/2305.13194)
   - [Данные и метрики](https://github.com/google-research-datasets/seahorse) от авторов 
- Обучение модели качества:
   - RU и EN данные взяты из статьи [_SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation_](https://arxiv.org/abs/2305.13194)
   - Для предсказания **Q6 Concise** модель-метрика обучена  из датасета статьи (самая высокоуровневая метрика из предложенных)
      - 10% данных использовалось для dev/test
      - 90% данных использовалось для обучения модели (обучено ДВЕ модели: открытая и закрытая. Каждая из моделей обучена на 60% данных от полного датасета).

**_Замечание:_**
На вход модели-метрике текст должен подаваться в следующем формате: `"Текст статьи:\n" + Text + "\n\n" + "Краткое содержание:\n" + Summary as metric_input`

### Формат результата выполненного задания
- `json lines` - в каждой строке json вида `{'id': AAA, 'summary': "BBB"}`

## Начало Работы

### Копирование
Для копирования файлов Проекта на локальный компьютер в папку *<your_dir_on_local_computer>* выполните:

```
    $ git clone git@github.com:dbadeev/habr_summarization.git <your_dir_on_local_computer>
```

### Описание файлов
* *requirements.txt* - список библиотек, необходимых для работы
* *summarization.ipynb* - ноутбук проекта  
* *models.py* - утилиты "чистки" текста твитов
* Папка *data*
  - *test_articles_clear_100.json* - файл со статьями из Habr, которые нужно суммаризовать
  - *train_data.json*  - файл с примерами различных суммаризаций с оценкой открытой моделью, которые можно использовать для дообучения при необхдимости
  - *train_llm.json* - файл с примерами удовлетворяющих дополнительным требованиям по длине лучших суммаризаций среди данных в _train_data.json_ для fewshot дообучения базовой модели YandexGP
  - *test_results_base.json* - файл с суммаризациями статей, полученных с помощью базовой (фундаментальной) модели YandexGPT
  - *test_results_fin.json* - файл с обновленными суммаризациями статей, полученных с помощью дообученной (fewshot) базовой модели YandexGPT
  - *test_output_jsonlines.json* - окончательный файл в требуемом формате с обновленными суммаризациями статей,полученных с помощью дообученной (fewshot) базовой модели YandexGPT
* *tweets.ipynb* - ноутбук проекта  
* *models.py* - утилиты суммаризации заданного текста

## Запуск
В файле *summarization.ipynb* приведена пошаговая реализация проекта с пояснениями и промежуточными результатами. 

